# MADE_CV2

История про то как меня подбросило на привате на 43 места вверх и почему это не случайность.

Я начал с mask-rcnn + crnn из бейзлайна Алексея Ярошенко. Получил 1.69 на привате с учётом того что я упростил процесс и экономил на обучении. Внимательно изучил, где модель больше всего ошибается. Увидел, что большинство ошибок - на первом этапе, то есть иногда номера не детектируются. Присмотрелся к тому, какие именно номера не детектируются, увидел что среди них очень много наклонённых на 30-90 градусов. Чтобы с этим бороться, принялся писать аугментации для этапа детекции с вращением. Для меня писать аугментацию было больно и долго: крутить надо и картинку, и ббоксы, и маски, а потом ещё и смотреть чтобы никто из них не вылез за область картинки. В итоге через albumentations с долгим допиливанием получилось. Помимо аугментации старался сделать модель максимально непохожей на первую: докинул регуляризацию, стал кропать градиенты, агрессивнее резал lr шедулером и т.д. В итоге модель проучилась всего половину эпохи и её пришлось остановить так как время поджимало. Понятно, что аугментация как расширение датасета при таком раскладе не сработала, но по идее модель должна была получиться более восприимчивой к наклонённым номерам. Проверил результаты - в целом стало хуже (в итоге эта модель показала 1.71 на привате), но сложные случаи в духе «номер лежит на сиденье внутри машины под углом 45 градусов» стали детектироваться.

Тогда я решил объединить предсказания обеих моделей. Применял такие правила:

* Если более точная модель (первая) не обнаружила ничего, взять предсказание второй
* Если менее точная модель (вторая) обнаружила больше номеров длиной 8+ символов, чем более точная, взять предсказание второй.
* В остальных случаях взять предсказание первой, более точной модели. Вот то же самое кодом:

```python
result = {}
for i, row in subm1.iterrows():
    values = str(row['plates_string']).split(' ')
    values_alt = str(row['plates_string_alt']).split(' ')
    values = [] if values[0].lower() == 'nan' else values
    values_alt = [] if values_alt[0].lower() == 'nan' else values_alt
    if not values and values_alt:
        actual = values_alt
    elif not values_alt and values:
        actual = values
    elif not values and not values_alt:
        actual = []
    elif len([v for v in values_alt if len(v)>7]) > len([v for v in values if len(v)>7]):
        actual = values_alt
    else:
        actual = values
    actual = ' '.join(actual)
    result[i] = {'file_name': row['file_name'], 'plates_string': actual}
total = pd.DataFrame.from_dict(result, orient='index')

```

Итог: 1.69 + 1.71 = 1.52 при объединении :)

# Почему это сработало?

Из разницы в скорах на паблике (0.5 - 1) и привате (1.5 - 4) постфактум можно сделать вывод, что организаторы отделили самые "сложные" случаи именно в приватную часть. Под "сложными" номерами я понимаю прежде всего те случаи, когда номера трудно детектируются. Из описания выше видно, что я целенаправленно с этим боролся. Кроме того, когда результат выбирается из предсказаний двух моделей, вероятность того, что хотя бы одна из них задетектирует номер, повышается. Интересно, что такое объединение предсказаний дало рост на паблике лишь во втором знаке после запятой, тогда как на привате скор улучшился на 0.17. Это можно объяснить тем же самым предположением, что в привате находятся самые сложные случаи.
